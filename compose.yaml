# Docker Compose stack to run the API, Redis and Mongo locally
x-health: &health_defaults
  interval: 15s
  timeout: 3s
  retries: 10
  start_period: 20s

services:
  mongo:
    # MongoDB stores conversation history and documents
    image: mongo:8.0
    restart: unless-stopped
    ports:
      - "27017:27017"
    volumes:
      - "mongo_data:/data/db"
    env_file: .env
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USERNAME:-root}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASSWORD:-changeme}
      MONGO_INITDB_DATABASE: ${MONGO_DATABASE:-smarthelperdb}
    healthcheck:
      <<: *health_defaults
      test: ["CMD", "mongosh", "--quiet", "--eval", "db.adminCommand('ping')"]

  redis:
    # Redis is used for the vector store and Celery broker
    image: bitnami/redis:7.0
    restart: unless-stopped
    environment:
      REDIS_PASSWORD: ${REDIS_PASSWORD}
    ports:
      - "6379:6379"
    healthcheck:
      <<: *health_defaults
      test:
        - CMD
        - redis-cli
        - ping

  celery_worker:
    # Processes scheduled tasks that update the vector store
    build:
      context: ./
      dockerfile: Dockerfile
      args:
        APT_CACHE_ID: apt-cache-worker
        UV_CACHE_ID: uv-cache-worker
    restart: unless-stopped
    env_file: .env
    environment:
      REDIS_URL: ${REDIS_URL}
      MONGO_URI: ${MONGO_URI:-mongodb://${MONGO_USERNAME}:${MONGO_PASSWORD}@mongo:27017}
      CRAWL_START_URL: ${CRAWL_START_URL:-https://mmvs.ru}
      CMAKE_ARGS: "-DLLAMA_CUBLAS=OFF -DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS -DLLAMA_NATIVE=ON"
      LLAMA_CPP_PYTHON_BUILD: "cmake"
      PIP_INDEX_URL: "https://download.pytorch.org/whl/cpu"
    command: ["uv", "run", "celery", "-A", "worker", "worker", "--loglevel=INFO"]
    depends_on:
      redis:
        condition: service_healthy
      mongo:
        condition: service_healthy
      celery_beat:
        condition: service_healthy
    volumes:
      - ./data/hf:/root/.cache/huggingface
    healthcheck:
      <<: *health_defaults
      test:
        - CMD-SHELL
        - test $(pgrep -fc celery) -ge 1

  celery_beat:
    # Scheduler for periodic vector store updates
    build:
      context: ./
      dockerfile: Dockerfile
      args:
        APT_CACHE_ID: apt-cache-beat
        UV_CACHE_ID: uv-cache-beat
    restart: unless-stopped
    env_file: .env
    command: ["uv", "run", "celery", "-A", "worker", "beat", "--loglevel=INFO"]
    depends_on:
      redis:
        condition: service_healthy
    environment:
      REDIS_URL: ${REDIS_URL}
      CMAKE_ARGS: "-DLLAMA_CUBLAS=OFF -DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS -DLLAMA_NATIVE=ON"
      LLAMA_CPP_PYTHON_BUILD: "cmake"
      PIP_INDEX_URL: "https://download.pytorch.org/whl/cpu"

    healthcheck:
      <<: *health_defaults
      test:
        - CMD-SHELL
        - test $(pgrep -fc "celery beat") -ge 1

  app:
    # FastAPI application exposing the LLM endpoints
    build:
      context: ./
      dockerfile: Dockerfile
      args:
        APT_CACHE_ID: apt-cache-app
        UV_CACHE_ID: uv-cache-app
    restart: unless-stopped
    env_file: .env
    ports:
      - "8000:8000"
    environment:
      REDIS_URL: ${REDIS_URL}
      APP_HOST: "0.0.0.0"
      APP_PORT: "8000"
      MONGO_URI: ${MONGO_URI:-mongodb://${MONGO_USERNAME}:${MONGO_PASSWORD}@mongo:27017}
      CRAWL_START_URL: ${CRAWL_START_URL:-https://mmvs.ru}
      CMAKE_ARGS: "-DLLAMA_CUBLAS=OFF -DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS -DLLAMA_NATIVE=ON"
      LLAMA_CPP_PYTHON_BUILD: "cmake"
      PIP_INDEX_URL: "https://download.pytorch.org/whl/cpu"
      PYTHONPATH: /app
    command: >
      sh -lc "
        uv run uvicorn app:app
        --host 0.0.0.0
        --port 8000
        --workers ${APP_WORKERS:-1}
        --timeout-keep-alive 30
      "
    volumes:
      - ./data/hf:/root/.cache/huggingface
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:${APP_PORT:-8000}/healthz || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 20
      start_period: 10s
    depends_on:
      mongo:
        condition: service_healthy
      redis:
        condition: service_healthy
      qdrant:
        condition: service_started

  qdrant:
    image: qdrant/qdrant
    restart: unless-stopped
    ports:
      - "6333:6333"
    volumes:
      - qdrant_data:/qdrant/storage


  telegram-bot:
    build:
      context: .
      dockerfile: docker/Dockerfile.tg_bot
    env_file: .env
    environment:
      PYTHONPATH: /app
    restart: unless-stopped
    depends_on:
      - app

volumes:
  mongo_data:
  qdrant_data:

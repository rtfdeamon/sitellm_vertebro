services:
  app:
    build:
      args:
        # Use prebuilt CUDA wheels for torch and llama-cpp-python
        PIP_EXTRA_INDEX_URL: "https://download.pytorch.org/whl/cu121 https://abetlen.github.io/llama-cpp-python/whl/cu121"
    environment:
      NVIDIA_VISIBLE_DEVICES: "all"
      NVIDIA_DRIVER_CAPABILITIES: "compute,utility"
    gpus: "all"

  celery_worker:
    build:
      args:
        PIP_EXTRA_INDEX_URL: "https://download.pytorch.org/whl/cu121 https://abetlen.github.io/llama-cpp-python/whl/cu121"
    environment:
      NVIDIA_VISIBLE_DEVICES: "all"
      NVIDIA_DRIVER_CAPABILITIES: "compute,utility"
    gpus: "all"
